{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maketree forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2dCFLWT31G2"
      },
      "source": [
        "## Import all packages and functions needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGevpW6_3k54"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z73zUN8O0K6j"
      },
      "source": [
        "## Decision tree class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyk6Mbvkysc7"
      },
      "source": [
        "class dtree:\n",
        "\t\"\"\" A basic Decision Tree\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\" Constructor \"\"\"\n",
        "\n",
        "\tdef read_data(self, filename):\n",
        "\t\tfid = open(filename, \"r\")\n",
        "\t\tdata = []\n",
        "\t\td = []\n",
        "\t\tfor line in fid.readlines():\n",
        "\t\t\td.append(line.strip())\n",
        "\t\tfor d1 in d:\n",
        "\t\t\tdata.append(d1.split(\",\"))\n",
        "\t\tfid.close()\n",
        "\n",
        "\t\tself.featureNames = data[0]\n",
        "\t\tself.featureNames = self.featureNames[:-1]\n",
        "\t\tdata = data[1:]\n",
        "\t\tself.classes = []\n",
        "\t\tfor d in range(len(data)):\n",
        "\t\t\tself.classes.append(data[d][-1])\n",
        "\t\t\tdata[d] = data[d][:-1]\n",
        "\n",
        "\t\treturn data, self.classes, self.featureNames\n",
        " \n",
        "\tdef classify(self, tree, datapoint):\n",
        "\t\tif type(tree) == type(\"string\"):\n",
        "\t\t\t# Have reached a leaf\n",
        "\t\t\treturn tree\n",
        "\t\telse:\n",
        "\t\t\ta = list(tree.keys())[0]\n",
        "\t\t\tfor i in range(len(self.featureNames)):\n",
        "\t\t\t\tif self.featureNames[i] == a:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\ttry:\n",
        "\t\t\t\tt = tree[a][datapoint[i]]\n",
        "\t\t\t\treturn self.classify(t, datapoint)\n",
        "\t\t\texcept:\n",
        "\t\t\t\treturn None\n",
        "\n",
        "\tdef classifyAll(self, tree, data):\n",
        "\t\tresults = []\n",
        "\t\tfor i in range(len(data)):\n",
        "\t\t\tresults.append(self.classify(tree, data[i]))\n",
        "\t\treturn results\n",
        "\n",
        "\tdef make_tree(self,\n",
        "\t\t\t\t  data,\n",
        "\t\t\t\t  classes,\n",
        "\t\t\t\t  featureNames,\n",
        "\t\t\t\t  maxlevel=-1,\n",
        "\t\t\t\t  level=0,\n",
        "\t\t\t\t  forest=0):\n",
        "\t\t\"\"\" The main function, which recursively constructs the tree\"\"\"\n",
        "\n",
        "\t\tnData = len(data)\n",
        "\t\tnFeatures = len(data[0])\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tself.featureNames\n",
        "\t\texcept:\n",
        "\t\t\tself.featureNames = featureNames\n",
        "\n",
        "\t\t# List the possible classes\n",
        "\t\tnewClasses = []\n",
        "\t\tfor aclass in classes:\n",
        "\t\t\tif newClasses.count(aclass) == 0:\n",
        "\t\t\t\tnewClasses.append(aclass)\n",
        "\n",
        "\t\t# Compute the default class (and total entropy)\n",
        "\t\tfrequency = np.zeros(len(newClasses))\n",
        "\n",
        "\t\ttotalEntropy = 0\n",
        "\t\tindex = 0\n",
        "\t\tfor aclass in newClasses:\n",
        "\t\t\tfrequency[index] = classes.count(aclass)\n",
        "\t\t\ttotalEntropy += self.calc_entropy(float(frequency[index]) / nData)\n",
        "\t\t\tindex += 1\n",
        "\n",
        "\t\tdefault = classes[np.argmax(frequency)]\n",
        "\n",
        "\t\tif nData == 0 or nFeatures == 0 or (maxlevel >= 0 and level > maxlevel):\n",
        "\t\t\t# Have reached an empty branch\n",
        "\t\t\treturn default\n",
        "\t\telif classes.count(classes[0]) == nData:\n",
        "\t\t\t# Only 1 class remains\n",
        "\t\t\treturn classes[0]\n",
        "\t\telse:\n",
        "\n",
        "\t\t\t# Choose which feature is best\n",
        "\t\t\tgain = np.zeros(nFeatures)\n",
        "\t\t\tfeatureSet = list(range(nFeatures))\n",
        "\t\t\tif forest != 0:\n",
        "\t\t\t\tnp.random.shuffle(featureSet)\n",
        "\t\t\t\tfeatureSet = featureSet[0:forest]\n",
        "\t\t\tfor feature in featureSet:\n",
        "\t\t\t\tg = self.calc_info_gain(data, classes, feature)\n",
        "\t\t\t\tgain[feature] = totalEntropy - g\n",
        "\n",
        "\t\t\tbestFeature = np.argmax(gain)\n",
        "\t\t\ttree = {featureNames[bestFeature]: {}}\n",
        "\n",
        "\t\t\t# List the values that bestFeature can take\n",
        "\t\t\tvalues = []\n",
        "\t\t\tfor datapoint in data:\n",
        "\t\t\t\tif datapoint[feature] not in values:\n",
        "\t\t\t\t\tvalues.append(datapoint[bestFeature])\n",
        "\n",
        "\t\t\tfor value in values:\n",
        "\t\t\t\t# Find the datapoints with each feature value\n",
        "\t\t\t\tnewData = []\n",
        "\t\t\t\tnewClasses = []\n",
        "\t\t\t\tindex = 0\n",
        "\t\t\t\tfor datapoint in data:\n",
        "\t\t\t\t\tif datapoint[bestFeature] == value:\n",
        "\t\t\t\t\t\tif bestFeature == 0:\n",
        "\t\t\t\t\t\t\tnewdatapoint = datapoint[1:]\n",
        "\t\t\t\t\t\t\tnewNames = featureNames[1:]\n",
        "\t\t\t\t\t\telif bestFeature == nFeatures:\n",
        "\t\t\t\t\t\t\tnewdatapoint = datapoint[:-1]\n",
        "\t\t\t\t\t\t\tnewNames = featureNames[:-1]\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tnewdatapoint = datapoint[:bestFeature]\n",
        "\t\t\t\t\t\t\t# newdatapoint.append(datapoint[bestFeature+1:])\n",
        "\t\t\t\t\t\t\tnewdatapoint = np.append(\n",
        "\t\t\t\t\t\t\t\tnewdatapoint, datapoint[bestFeature + 1:])\n",
        "\t\t\t\t\t\t\tnewNames = featureNames[:bestFeature]\n",
        "\t\t\t\t\t\t\t# newNames.append(featureNames[bestFeature+1:])\n",
        "\t\t\t\t\t\t\tnewNames = np.append(\n",
        "\t\t\t\t\t\t\t\tnewNames, featureNames[bestFeature + 1:])\n",
        "\t\t\t\t\t\tnewData.append(newdatapoint)\n",
        "\t\t\t\t\t\tnewClasses.append(classes[index])\n",
        "\t\t\t\t\tindex += 1\n",
        "\n",
        "\t\t\t\t# Now recurse to the next level\n",
        "\t\t\t\tsubtree = self.make_tree(newData, newClasses, newNames, maxlevel, level + 1, forest)\n",
        "\n",
        "\t\t\t\t# And on returning, add the subtree on to the tree\n",
        "\t\t\t\ttree[featureNames[bestFeature]][value] = subtree\n",
        "\n",
        "\t\t\treturn tree\n",
        "\n",
        "\tdef printTree(self, tree, name):\n",
        "\t\tif type(tree) == dict:\n",
        "\t\t\tprint(name, tree.keys()[0])\n",
        "\t\t\tfor item in tree.values()[0].keys():\n",
        "\t\t\t\tprint(name, item)\n",
        "\t\t\t\tself.printTree(tree.values()[0][item], name + \"\\t\")\n",
        "\t\telse:\n",
        "\t\t\tprint(name, \"\\t->\\t\", tree)\n",
        "\n",
        "\tdef calc_entropy(self, p):\n",
        "\t\tif p != 0:\n",
        "\t\t\treturn -p * np.log2(p)\n",
        "\t\telse:\n",
        "\t\t\treturn 0\n",
        "\n",
        "\tdef calc_info_gain(self, data, classes, feature):\n",
        "\n",
        "\t\t# Calculates the information gain based on entropy\n",
        "\t\tgain = 0\n",
        "\t\tnData = len(data)\n",
        "\n",
        "\t\t# List the values that feature can take\n",
        "\n",
        "\t\tvalues = []\n",
        "\t\tfor datapoint in data:\n",
        "\t\t\tif datapoint[feature] not in values:\n",
        "\t\t\t\tvalues.append(datapoint[feature])\n",
        "\n",
        "\t\tfeatureCounts = np.zeros(len(values))\n",
        "\t\tentropy = np.zeros(len(values))\n",
        "\t\tvalueIndex = 0\n",
        "\t\t# Find where those values appear in data[feature] and the corresponding class\n",
        "\t\tfor value in values:\n",
        "\t\t\tdataIndex = 0\n",
        "\t\t\tnewClasses = []\n",
        "\t\t\tfor datapoint in data:\n",
        "\t\t\t\tif datapoint[feature] == value:\n",
        "\t\t\t\t\tfeatureCounts[valueIndex] += 1\n",
        "\t\t\t\t\tnewClasses.append(classes[dataIndex])\n",
        "\t\t\t\tdataIndex += 1\n",
        "\n",
        "\t\t\t# Get the values in newClasses\n",
        "\t\t\tclassValues = []\n",
        "\t\t\tfor aclass in newClasses:\n",
        "\t\t\t\tif classValues.count(aclass) == 0:\n",
        "\t\t\t\t\tclassValues.append(aclass)\n",
        "\n",
        "\t\t\tclassCounts = np.zeros(len(classValues))\n",
        "\t\t\tclassIndex = 0\n",
        "\t\t\tfor classValue in classValues:\n",
        "\t\t\t\tfor aclass in newClasses:\n",
        "\t\t\t\t\tif aclass == classValue:\n",
        "\t\t\t\t\t\tclassCounts[classIndex] += 1\n",
        "\t\t\t\tclassIndex += 1\n",
        "\n",
        "\t\t\tfor classIndex in range(len(classValues)):\n",
        "\t\t\t\tentropy[valueIndex] += self.calc_entropy(\n",
        "\t\t\t\t\tfloat(classCounts[classIndex]) / np.sum(classCounts))\n",
        "\n",
        "\t\t\t# Computes the entropy\n",
        "\t\t\tgain = gain + float(\n",
        "\t\t\t\tfeatureCounts[valueIndex]) / nData * entropy[valueIndex]\n",
        "\t\t\tvalueIndex += 1\n",
        "\t\treturn gain"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwD3SlLJyuSA"
      },
      "source": [
        "## Testing decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAJKENqOypjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b358ceb4-1a0a-4f8c-8a9a-b702ed9fe3c8"
      },
      "source": [
        "tree = dtree()\n",
        "data = np.genfromtxt('/content/drive/MyDrive/B455/data/breast-cancer-wisconsin.data', delimiter=',')\n",
        "names = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n",
        "\n",
        "data = data[:,1:]\n",
        "train_data, test_data = train_test_split(x, test_size=0.2, random_state=55)\n",
        "\n",
        "n_trees = 10\n",
        "m_features = int(len(names) / 2)\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "forest = [dtree()] * n_trees\n",
        "#creates bootstraps for each tree to use\n",
        "bootstraps = [rng.choice(train_data, size=train_data.shape[0], replace=True, axis=0) for i in range(n_trees)]\n",
        "#will store the completed trees\n",
        "complete_forest = [None] * n_trees\n",
        "\n",
        "for i in range(n_trees):\n",
        "  dat = bootstraps[i][:,:-1].tolist()\n",
        "  y = bootstraps[i][:,-1].tolist()\n",
        "  \n",
        "  #builds and stores the trees\n",
        "  #this errors for some reason that I can't figure out. The indenting is weird in the dtree class so I can't add lines to debug\n",
        "  complete_forest[i] = forest[i].make_tree(dat, y, names, forest=m_features)\n",
        "\n",
        "#majority voting for predictions\n",
        "dat = test_data[:,:-1].tolist()\n",
        "cls = test_data[:,-1].tolist()\n",
        "\n",
        "predictions = np.zeros(n_trees)\n",
        "for i in range(n_trees):\n",
        "  predictions[i] = forest[i].classifyAll(complete_forest[i], dat)\n",
        "\n",
        "pred = np.ndarray(prediction).max(axis=0)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-70f5a052e851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m#builds and stores the trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m#this errors for some reason that I can't figure out. The indenting is weird in the dtree class so I can't add lines to debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mcomplete_forest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#majority voting for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-b1c845aa3dde>\u001b[0m in \u001b[0;36mmake_tree\u001b[0;34m(self, data, classes, featureNames, maxlevel, level, forest)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                 \u001b[0;31m# Now recurse to the next level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                                 \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewClasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                 \u001b[0;31m# And on returning, add the subtree on to the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-b1c845aa3dde>\u001b[0m in \u001b[0;36mmake_tree\u001b[0;34m(self, data, classes, featureNames, maxlevel, level, forest)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                 \u001b[0;31m# Now recurse to the next level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                                 \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewClasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                 \u001b[0;31m# And on returning, add the subtree on to the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-b1c845aa3dde>\u001b[0m in \u001b[0;36mmake_tree\u001b[0;34m(self, data, classes, featureNames, maxlevel, level, forest)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mnData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mnFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}