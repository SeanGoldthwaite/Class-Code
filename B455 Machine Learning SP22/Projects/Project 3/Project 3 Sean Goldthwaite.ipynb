{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 3 - Sean Goldthwaite.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9122
        },
        "id": "Hf37ZVdJRdJ2",
        "outputId": "95e87127-9e39-4ef9-c931-25f98de22700"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def main():\n",
        "  #load data\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "  y_train = np.vstack([vectorize(item) for item in y_train])\n",
        "  y_test = np.vstack([vectorize(item) for item in y_test])\n",
        "\n",
        "  input_shape = x_train.shape[1:]\n",
        "  output_shape = y_train.shape[1:]\n",
        "  print(f'Input shape: {input_shape}')\n",
        "  print(f'Output shape: {output_shape}')\n",
        "\n",
        "  train_length = x_train.shape[0]\n",
        "  test_length = x_test.shape[0]\n",
        "\n",
        "  print(f'Num training data: {train_length}')\n",
        "  print(f'Num testing data: {test_length}')\n",
        "\n",
        "  #6-fold cross validation\n",
        "  batch_size = int(train_length / 5)\n",
        "\n",
        "  # input = tf.keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
        "  # flatten = tf.keras.layers.Flatten()\n",
        "  # hidden_one = tf.keras.layers.Dense(1000, activation=tf.nn.relu, use_bias=True)\n",
        "  # hidden_two = tf.keras.layers.Dense(100, activation=tf.nn.relu, use_bias=True)\n",
        "  # output = tf.keras.layers.Dense(10, activation=tf.nn.softmax, use_bias=True)\n",
        "\n",
        "  #model initialization\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Input(shape=input_shape)) #input\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1000, activation=tf.nn.relu, use_bias=True)) #hidden\n",
        "  model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu, use_bias=True)) #hidden\n",
        "  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax, use_bias=False)) #output\n",
        "\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.5)\n",
        "  loss = tf.keras.losses.MeanSquaredError()\n",
        "  metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metric, steps_per_execution=5)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  #training process\n",
        "  epochs = 1000\n",
        "\n",
        "  model_history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=1).history\n",
        "\n",
        "  cat_accuracy = model_history['categorical_accuracy']\n",
        "  val_cat_accuracy = model_history['val_categorical_accuracy']\n",
        "  \n",
        "  plt.plot(range(epochs), cat_accuracy, color='r')\n",
        "  plt.plot(range(epochs), val_cat_accuracy, color='b')\n",
        "\n",
        "def vectorize(n):\n",
        "  res = np.zeros(10)\n",
        "  res[n] = 1.0\n",
        "  return res\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (32, 32, 3)\n",
            "Output shape: (10,)\n",
            "Num training data: 50000\n",
            "Num testing data: 10000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              3073000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               100100    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1000      \n",
            "=================================================================\n",
            "Total params: 3,174,100\n",
            "Trainable params: 3,174,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.1743 - categorical_accuracy: 0.1195 - val_loss: 0.1723 - val_categorical_accuracy: 0.1271\n",
            "Epoch 2/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1720 - categorical_accuracy: 0.1295 - val_loss: 0.1697 - val_categorical_accuracy: 0.1410\n",
            "Epoch 3/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1692 - categorical_accuracy: 0.1446 - val_loss: 0.1682 - val_categorical_accuracy: 0.1501\n",
            "Epoch 4/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1682 - categorical_accuracy: 0.1507 - val_loss: 0.1676 - val_categorical_accuracy: 0.1540\n",
            "Epoch 5/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1673 - categorical_accuracy: 0.1556 - val_loss: 0.1670 - val_categorical_accuracy: 0.1569\n",
            "Epoch 6/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1664 - categorical_accuracy: 0.1600 - val_loss: 0.1651 - val_categorical_accuracy: 0.1663\n",
            "Epoch 7/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1661 - categorical_accuracy: 0.1625 - val_loss: 0.1659 - val_categorical_accuracy: 0.1636\n",
            "Epoch 8/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1655 - categorical_accuracy: 0.1661 - val_loss: 0.1655 - val_categorical_accuracy: 0.1661\n",
            "Epoch 9/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1650 - categorical_accuracy: 0.1676 - val_loss: 0.1655 - val_categorical_accuracy: 0.1645\n",
            "Epoch 10/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1642 - categorical_accuracy: 0.1721 - val_loss: 0.1632 - val_categorical_accuracy: 0.1766\n",
            "Epoch 11/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1636 - categorical_accuracy: 0.1738 - val_loss: 0.1629 - val_categorical_accuracy: 0.1784\n",
            "Epoch 12/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1633 - categorical_accuracy: 0.1759 - val_loss: 0.1624 - val_categorical_accuracy: 0.1789\n",
            "Epoch 13/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1629 - categorical_accuracy: 0.1768 - val_loss: 0.1634 - val_categorical_accuracy: 0.1754\n",
            "Epoch 14/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1624 - categorical_accuracy: 0.1796 - val_loss: 0.1616 - val_categorical_accuracy: 0.1839\n",
            "Epoch 15/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1617 - categorical_accuracy: 0.1825 - val_loss: 0.1613 - val_categorical_accuracy: 0.1847\n",
            "Epoch 16/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1611 - categorical_accuracy: 0.1853 - val_loss: 0.1603 - val_categorical_accuracy: 0.1886\n",
            "Epoch 17/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1604 - categorical_accuracy: 0.1888 - val_loss: 0.1607 - val_categorical_accuracy: 0.1877\n",
            "Epoch 18/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1600 - categorical_accuracy: 0.1907 - val_loss: 0.1599 - val_categorical_accuracy: 0.1912\n",
            "Epoch 19/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1600 - categorical_accuracy: 0.1909 - val_loss: 0.1597 - val_categorical_accuracy: 0.1932\n",
            "Epoch 20/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1596 - categorical_accuracy: 0.1922 - val_loss: 0.1597 - val_categorical_accuracy: 0.1914\n",
            "Epoch 21/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1592 - categorical_accuracy: 0.1944 - val_loss: 0.1588 - val_categorical_accuracy: 0.1961\n",
            "Epoch 22/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1587 - categorical_accuracy: 0.1969 - val_loss: 0.1589 - val_categorical_accuracy: 0.1959\n",
            "Epoch 23/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1585 - categorical_accuracy: 0.1978 - val_loss: 0.1591 - val_categorical_accuracy: 0.1949\n",
            "Epoch 24/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1580 - categorical_accuracy: 0.1995 - val_loss: 0.1582 - val_categorical_accuracy: 0.1984\n",
            "Epoch 25/250\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.1576 - categorical_accuracy: 0.2021 - val_loss: 0.1572 - val_categorical_accuracy: 0.2041\n",
            "Epoch 26/250\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.1575 - categorical_accuracy: 0.2029 - val_loss: 0.1581 - val_categorical_accuracy: 0.1997\n",
            "Epoch 27/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1573 - categorical_accuracy: 0.2046 - val_loss: 0.1577 - val_categorical_accuracy: 0.2025\n",
            "Epoch 28/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1568 - categorical_accuracy: 0.2069 - val_loss: 0.1568 - val_categorical_accuracy: 0.2069\n",
            "Epoch 29/250\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.1564 - categorical_accuracy: 0.2084 - val_loss: 0.1563 - val_categorical_accuracy: 0.2088\n",
            "Epoch 30/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1557 - categorical_accuracy: 0.2114 - val_loss: 0.1566 - val_categorical_accuracy: 0.2074\n",
            "Epoch 31/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1557 - categorical_accuracy: 0.2116 - val_loss: 0.1555 - val_categorical_accuracy: 0.2134\n",
            "Epoch 32/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1548 - categorical_accuracy: 0.2163 - val_loss: 0.1556 - val_categorical_accuracy: 0.2130\n",
            "Epoch 33/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1553 - categorical_accuracy: 0.2139 - val_loss: 0.1550 - val_categorical_accuracy: 0.2147\n",
            "Epoch 34/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1546 - categorical_accuracy: 0.2171 - val_loss: 0.1547 - val_categorical_accuracy: 0.2179\n",
            "Epoch 35/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1546 - categorical_accuracy: 0.2176 - val_loss: 0.1548 - val_categorical_accuracy: 0.2175\n",
            "Epoch 36/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1542 - categorical_accuracy: 0.2196 - val_loss: 0.1546 - val_categorical_accuracy: 0.2181\n",
            "Epoch 37/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1538 - categorical_accuracy: 0.2220 - val_loss: 0.1544 - val_categorical_accuracy: 0.2188\n",
            "Epoch 38/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1535 - categorical_accuracy: 0.2241 - val_loss: 0.1545 - val_categorical_accuracy: 0.2178\n",
            "Epoch 39/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1537 - categorical_accuracy: 0.2223 - val_loss: 0.1544 - val_categorical_accuracy: 0.2191\n",
            "Epoch 40/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1535 - categorical_accuracy: 0.2237 - val_loss: 0.1542 - val_categorical_accuracy: 0.2200\n",
            "Epoch 41/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1531 - categorical_accuracy: 0.2256 - val_loss: 0.1542 - val_categorical_accuracy: 0.2209\n",
            "Epoch 42/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1535 - categorical_accuracy: 0.2235 - val_loss: 0.1538 - val_categorical_accuracy: 0.2213\n",
            "Epoch 43/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1530 - categorical_accuracy: 0.2258 - val_loss: 0.1539 - val_categorical_accuracy: 0.2216\n",
            "Epoch 44/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1529 - categorical_accuracy: 0.2268 - val_loss: 0.1542 - val_categorical_accuracy: 0.2210\n",
            "Epoch 45/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1532 - categorical_accuracy: 0.2251 - val_loss: 0.1537 - val_categorical_accuracy: 0.2225\n",
            "Epoch 46/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1527 - categorical_accuracy: 0.2280 - val_loss: 0.1537 - val_categorical_accuracy: 0.2223\n",
            "Epoch 47/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1530 - categorical_accuracy: 0.2265 - val_loss: 0.1536 - val_categorical_accuracy: 0.2230\n",
            "Epoch 48/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1523 - categorical_accuracy: 0.2299 - val_loss: 0.1537 - val_categorical_accuracy: 0.2237\n",
            "Epoch 49/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1530 - categorical_accuracy: 0.2255 - val_loss: 0.1533 - val_categorical_accuracy: 0.2244\n",
            "Epoch 50/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1526 - categorical_accuracy: 0.2288 - val_loss: 0.1535 - val_categorical_accuracy: 0.2235\n",
            "Epoch 51/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1530 - categorical_accuracy: 0.2260 - val_loss: 0.1536 - val_categorical_accuracy: 0.2233\n",
            "Epoch 52/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1526 - categorical_accuracy: 0.2275 - val_loss: 0.1532 - val_categorical_accuracy: 0.2252\n",
            "Epoch 53/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1521 - categorical_accuracy: 0.2310 - val_loss: 0.1531 - val_categorical_accuracy: 0.2258\n",
            "Epoch 54/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1518 - categorical_accuracy: 0.2320 - val_loss: 0.1531 - val_categorical_accuracy: 0.2261\n",
            "Epoch 55/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1518 - categorical_accuracy: 0.2321 - val_loss: 0.1524 - val_categorical_accuracy: 0.2283\n",
            "Epoch 56/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1520 - categorical_accuracy: 0.2316 - val_loss: 0.1526 - val_categorical_accuracy: 0.2287\n",
            "Epoch 57/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1514 - categorical_accuracy: 0.2343 - val_loss: 0.1529 - val_categorical_accuracy: 0.2271\n",
            "Epoch 58/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1515 - categorical_accuracy: 0.2341 - val_loss: 0.1524 - val_categorical_accuracy: 0.2290\n",
            "Epoch 59/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1514 - categorical_accuracy: 0.2349 - val_loss: 0.1519 - val_categorical_accuracy: 0.2315\n",
            "Epoch 60/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1517 - categorical_accuracy: 0.2332 - val_loss: 0.1520 - val_categorical_accuracy: 0.2305\n",
            "Epoch 61/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1513 - categorical_accuracy: 0.2348 - val_loss: 0.1526 - val_categorical_accuracy: 0.2282\n",
            "Epoch 62/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1517 - categorical_accuracy: 0.2328 - val_loss: 0.1520 - val_categorical_accuracy: 0.2311\n",
            "Epoch 63/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1506 - categorical_accuracy: 0.2381 - val_loss: 0.1521 - val_categorical_accuracy: 0.2322\n",
            "Epoch 64/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1512 - categorical_accuracy: 0.2361 - val_loss: 0.1525 - val_categorical_accuracy: 0.2287\n",
            "Epoch 65/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1510 - categorical_accuracy: 0.2366 - val_loss: 0.1523 - val_categorical_accuracy: 0.2303\n",
            "Epoch 66/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1511 - categorical_accuracy: 0.2363 - val_loss: 0.1519 - val_categorical_accuracy: 0.2322\n",
            "Epoch 67/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1503 - categorical_accuracy: 0.2397 - val_loss: 0.1515 - val_categorical_accuracy: 0.2340\n",
            "Epoch 68/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1502 - categorical_accuracy: 0.2405 - val_loss: 0.1516 - val_categorical_accuracy: 0.2329\n",
            "Epoch 69/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1505 - categorical_accuracy: 0.2386 - val_loss: 0.1519 - val_categorical_accuracy: 0.2316\n",
            "Epoch 70/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1500 - categorical_accuracy: 0.2414 - val_loss: 0.1521 - val_categorical_accuracy: 0.2311\n",
            "Epoch 71/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1506 - categorical_accuracy: 0.2382 - val_loss: 0.1514 - val_categorical_accuracy: 0.2341\n",
            "Epoch 72/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1501 - categorical_accuracy: 0.2411 - val_loss: 0.1523 - val_categorical_accuracy: 0.2292\n",
            "Epoch 73/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1504 - categorical_accuracy: 0.2393 - val_loss: 0.1516 - val_categorical_accuracy: 0.2334\n",
            "Epoch 74/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1503 - categorical_accuracy: 0.2402 - val_loss: 0.1512 - val_categorical_accuracy: 0.2355\n",
            "Epoch 75/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1499 - categorical_accuracy: 0.2413 - val_loss: 0.1513 - val_categorical_accuracy: 0.2347\n",
            "Epoch 76/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1496 - categorical_accuracy: 0.2433 - val_loss: 0.1513 - val_categorical_accuracy: 0.2348\n",
            "Epoch 77/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1496 - categorical_accuracy: 0.2434 - val_loss: 0.1513 - val_categorical_accuracy: 0.2354\n",
            "Epoch 78/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1495 - categorical_accuracy: 0.2440 - val_loss: 0.1514 - val_categorical_accuracy: 0.2347\n",
            "Epoch 79/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1495 - categorical_accuracy: 0.2442 - val_loss: 0.1515 - val_categorical_accuracy: 0.2335\n",
            "Epoch 80/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1496 - categorical_accuracy: 0.2435 - val_loss: 0.1508 - val_categorical_accuracy: 0.2385\n",
            "Epoch 81/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1498 - categorical_accuracy: 0.2426 - val_loss: 0.1507 - val_categorical_accuracy: 0.2382\n",
            "Epoch 82/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1492 - categorical_accuracy: 0.2452 - val_loss: 0.1509 - val_categorical_accuracy: 0.2370\n",
            "Epoch 83/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1491 - categorical_accuracy: 0.2462 - val_loss: 0.1509 - val_categorical_accuracy: 0.2375\n",
            "Epoch 84/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1491 - categorical_accuracy: 0.2460 - val_loss: 0.1509 - val_categorical_accuracy: 0.2366\n",
            "Epoch 85/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1488 - categorical_accuracy: 0.2475 - val_loss: 0.1506 - val_categorical_accuracy: 0.2395\n",
            "Epoch 86/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1490 - categorical_accuracy: 0.2463 - val_loss: 0.1508 - val_categorical_accuracy: 0.2379\n",
            "Epoch 87/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1498 - categorical_accuracy: 0.2425 - val_loss: 0.1508 - val_categorical_accuracy: 0.2370\n",
            "Epoch 88/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1492 - categorical_accuracy: 0.2457 - val_loss: 0.1513 - val_categorical_accuracy: 0.2346\n",
            "Epoch 89/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1486 - categorical_accuracy: 0.2483 - val_loss: 0.1512 - val_categorical_accuracy: 0.2358\n",
            "Epoch 90/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1490 - categorical_accuracy: 0.2470 - val_loss: 0.1503 - val_categorical_accuracy: 0.2399\n",
            "Epoch 91/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1486 - categorical_accuracy: 0.2482 - val_loss: 0.1504 - val_categorical_accuracy: 0.2405\n",
            "Epoch 92/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1494 - categorical_accuracy: 0.2448 - val_loss: 0.1504 - val_categorical_accuracy: 0.2392\n",
            "Epoch 93/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1486 - categorical_accuracy: 0.2488 - val_loss: 0.1503 - val_categorical_accuracy: 0.2398\n",
            "Epoch 94/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1489 - categorical_accuracy: 0.2471 - val_loss: 0.1510 - val_categorical_accuracy: 0.2368\n",
            "Epoch 95/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1489 - categorical_accuracy: 0.2477 - val_loss: 0.1508 - val_categorical_accuracy: 0.2380\n",
            "Epoch 96/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1490 - categorical_accuracy: 0.2464 - val_loss: 0.1507 - val_categorical_accuracy: 0.2382\n",
            "Epoch 97/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1485 - categorical_accuracy: 0.2492 - val_loss: 0.1505 - val_categorical_accuracy: 0.2391\n",
            "Epoch 98/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1481 - categorical_accuracy: 0.2506 - val_loss: 0.1500 - val_categorical_accuracy: 0.2419\n",
            "Epoch 99/250\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.1481 - categorical_accuracy: 0.2511 - val_loss: 0.1496 - val_categorical_accuracy: 0.2427\n",
            "Epoch 100/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1481 - categorical_accuracy: 0.2516 - val_loss: 0.1505 - val_categorical_accuracy: 0.2393\n",
            "Epoch 101/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1479 - categorical_accuracy: 0.2521 - val_loss: 0.1498 - val_categorical_accuracy: 0.2424\n",
            "Epoch 102/250\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.1485 - categorical_accuracy: 0.2489 - val_loss: 0.1499 - val_categorical_accuracy: 0.2422\n",
            "Epoch 103/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1486 - categorical_accuracy: 0.2486 - val_loss: 0.1504 - val_categorical_accuracy: 0.2397\n",
            "Epoch 104/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1476 - categorical_accuracy: 0.2532 - val_loss: 0.1501 - val_categorical_accuracy: 0.2413\n",
            "Epoch 105/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1476 - categorical_accuracy: 0.2535 - val_loss: 0.1498 - val_categorical_accuracy: 0.2428\n",
            "Epoch 106/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1478 - categorical_accuracy: 0.2526 - val_loss: 0.1495 - val_categorical_accuracy: 0.2437\n",
            "Epoch 107/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1476 - categorical_accuracy: 0.2540 - val_loss: 0.1500 - val_categorical_accuracy: 0.2419\n",
            "Epoch 108/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1473 - categorical_accuracy: 0.2552 - val_loss: 0.1500 - val_categorical_accuracy: 0.2420\n",
            "Epoch 109/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1476 - categorical_accuracy: 0.2536 - val_loss: 0.1496 - val_categorical_accuracy: 0.2435\n",
            "Epoch 110/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1475 - categorical_accuracy: 0.2542 - val_loss: 0.1500 - val_categorical_accuracy: 0.2419\n",
            "Epoch 111/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1481 - categorical_accuracy: 0.2514 - val_loss: 0.1498 - val_categorical_accuracy: 0.2429\n",
            "Epoch 112/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1473 - categorical_accuracy: 0.2552 - val_loss: 0.1501 - val_categorical_accuracy: 0.2417\n",
            "Epoch 113/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1470 - categorical_accuracy: 0.2567 - val_loss: 0.1495 - val_categorical_accuracy: 0.2442\n",
            "Epoch 114/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1478 - categorical_accuracy: 0.2526 - val_loss: 0.1496 - val_categorical_accuracy: 0.2433\n",
            "Epoch 115/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1471 - categorical_accuracy: 0.2564 - val_loss: 0.1501 - val_categorical_accuracy: 0.2412\n",
            "Epoch 116/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1474 - categorical_accuracy: 0.2540 - val_loss: 0.1499 - val_categorical_accuracy: 0.2425\n",
            "Epoch 117/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1474 - categorical_accuracy: 0.2556 - val_loss: 0.1496 - val_categorical_accuracy: 0.2430\n",
            "Epoch 118/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1472 - categorical_accuracy: 0.2558 - val_loss: 0.1496 - val_categorical_accuracy: 0.2439\n",
            "Epoch 119/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1477 - categorical_accuracy: 0.2534 - val_loss: 0.1491 - val_categorical_accuracy: 0.2464\n",
            "Epoch 120/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1472 - categorical_accuracy: 0.2560 - val_loss: 0.1493 - val_categorical_accuracy: 0.2454\n",
            "Epoch 121/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1470 - categorical_accuracy: 0.2572 - val_loss: 0.1492 - val_categorical_accuracy: 0.2461\n",
            "Epoch 122/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1470 - categorical_accuracy: 0.2561 - val_loss: 0.1494 - val_categorical_accuracy: 0.2446\n",
            "Epoch 123/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1468 - categorical_accuracy: 0.2578 - val_loss: 0.1489 - val_categorical_accuracy: 0.2473\n",
            "Epoch 124/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1467 - categorical_accuracy: 0.2579 - val_loss: 0.1490 - val_categorical_accuracy: 0.2466\n",
            "Epoch 125/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1468 - categorical_accuracy: 0.2576 - val_loss: 0.1492 - val_categorical_accuracy: 0.2462\n",
            "Epoch 126/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1471 - categorical_accuracy: 0.2563 - val_loss: 0.1496 - val_categorical_accuracy: 0.2443\n",
            "Epoch 127/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1473 - categorical_accuracy: 0.2554 - val_loss: 0.1493 - val_categorical_accuracy: 0.2453\n",
            "Epoch 128/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1469 - categorical_accuracy: 0.2575 - val_loss: 0.1490 - val_categorical_accuracy: 0.2469\n",
            "Epoch 129/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1464 - categorical_accuracy: 0.2597 - val_loss: 0.1493 - val_categorical_accuracy: 0.2458\n",
            "Epoch 130/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1467 - categorical_accuracy: 0.2584 - val_loss: 0.1489 - val_categorical_accuracy: 0.2465\n",
            "Epoch 131/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1463 - categorical_accuracy: 0.2598 - val_loss: 0.1493 - val_categorical_accuracy: 0.2458\n",
            "Epoch 132/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1464 - categorical_accuracy: 0.2596 - val_loss: 0.1487 - val_categorical_accuracy: 0.2476\n",
            "Epoch 133/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1464 - categorical_accuracy: 0.2594 - val_loss: 0.1492 - val_categorical_accuracy: 0.2452\n",
            "Epoch 134/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1463 - categorical_accuracy: 0.2599 - val_loss: 0.1494 - val_categorical_accuracy: 0.2448\n",
            "Epoch 135/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1468 - categorical_accuracy: 0.2574 - val_loss: 0.1493 - val_categorical_accuracy: 0.2453\n",
            "Epoch 136/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1462 - categorical_accuracy: 0.2607 - val_loss: 0.1488 - val_categorical_accuracy: 0.2471\n",
            "Epoch 137/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1467 - categorical_accuracy: 0.2582 - val_loss: 0.1485 - val_categorical_accuracy: 0.2497\n",
            "Epoch 138/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1462 - categorical_accuracy: 0.2607 - val_loss: 0.1487 - val_categorical_accuracy: 0.2481\n",
            "Epoch 139/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1466 - categorical_accuracy: 0.2581 - val_loss: 0.1491 - val_categorical_accuracy: 0.2465\n",
            "Epoch 140/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1462 - categorical_accuracy: 0.2610 - val_loss: 0.1493 - val_categorical_accuracy: 0.2455\n",
            "Epoch 141/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1462 - categorical_accuracy: 0.2612 - val_loss: 0.1485 - val_categorical_accuracy: 0.2489\n",
            "Epoch 142/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1463 - categorical_accuracy: 0.2604 - val_loss: 0.1487 - val_categorical_accuracy: 0.2478\n",
            "Epoch 143/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1464 - categorical_accuracy: 0.2597 - val_loss: 0.1483 - val_categorical_accuracy: 0.2499\n",
            "Epoch 144/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1459 - categorical_accuracy: 0.2623 - val_loss: 0.1494 - val_categorical_accuracy: 0.2457\n",
            "Epoch 145/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1461 - categorical_accuracy: 0.2606 - val_loss: 0.1490 - val_categorical_accuracy: 0.2456\n",
            "Epoch 146/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1459 - categorical_accuracy: 0.2619 - val_loss: 0.1493 - val_categorical_accuracy: 0.2457\n",
            "Epoch 147/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1461 - categorical_accuracy: 0.2612 - val_loss: 0.1482 - val_categorical_accuracy: 0.2508\n",
            "Epoch 148/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1465 - categorical_accuracy: 0.2594 - val_loss: 0.1491 - val_categorical_accuracy: 0.2457\n",
            "Epoch 149/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1461 - categorical_accuracy: 0.2611 - val_loss: 0.1489 - val_categorical_accuracy: 0.2479\n",
            "Epoch 150/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1464 - categorical_accuracy: 0.2600 - val_loss: 0.1489 - val_categorical_accuracy: 0.2471\n",
            "Epoch 151/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1455 - categorical_accuracy: 0.2641 - val_loss: 0.1486 - val_categorical_accuracy: 0.2485\n",
            "Epoch 152/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1463 - categorical_accuracy: 0.2604 - val_loss: 0.1480 - val_categorical_accuracy: 0.2518\n",
            "Epoch 153/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1454 - categorical_accuracy: 0.2647 - val_loss: 0.1489 - val_categorical_accuracy: 0.2480\n",
            "Epoch 154/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1461 - categorical_accuracy: 0.2613 - val_loss: 0.1491 - val_categorical_accuracy: 0.2461\n",
            "Epoch 155/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1460 - categorical_accuracy: 0.2618 - val_loss: 0.1482 - val_categorical_accuracy: 0.2506\n",
            "Epoch 156/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1456 - categorical_accuracy: 0.2638 - val_loss: 0.1482 - val_categorical_accuracy: 0.2506\n",
            "Epoch 157/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1457 - categorical_accuracy: 0.2627 - val_loss: 0.1489 - val_categorical_accuracy: 0.2479\n",
            "Epoch 158/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1461 - categorical_accuracy: 0.2615 - val_loss: 0.1484 - val_categorical_accuracy: 0.2497\n",
            "Epoch 159/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1453 - categorical_accuracy: 0.2649 - val_loss: 0.1483 - val_categorical_accuracy: 0.2514\n",
            "Epoch 160/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1454 - categorical_accuracy: 0.2643 - val_loss: 0.1481 - val_categorical_accuracy: 0.2516\n",
            "Epoch 161/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1452 - categorical_accuracy: 0.2656 - val_loss: 0.1482 - val_categorical_accuracy: 0.2507\n",
            "Epoch 162/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1454 - categorical_accuracy: 0.2646 - val_loss: 0.1483 - val_categorical_accuracy: 0.2514\n",
            "Epoch 163/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1453 - categorical_accuracy: 0.2652 - val_loss: 0.1483 - val_categorical_accuracy: 0.2500\n",
            "Epoch 164/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1450 - categorical_accuracy: 0.2665 - val_loss: 0.1484 - val_categorical_accuracy: 0.2490\n",
            "Epoch 165/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1456 - categorical_accuracy: 0.2631 - val_loss: 0.1478 - val_categorical_accuracy: 0.2519\n",
            "Epoch 166/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1457 - categorical_accuracy: 0.2632 - val_loss: 0.1476 - val_categorical_accuracy: 0.2542\n",
            "Epoch 167/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1455 - categorical_accuracy: 0.2641 - val_loss: 0.1486 - val_categorical_accuracy: 0.2488\n",
            "Epoch 168/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1452 - categorical_accuracy: 0.2657 - val_loss: 0.1485 - val_categorical_accuracy: 0.2495\n",
            "Epoch 169/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1453 - categorical_accuracy: 0.2655 - val_loss: 0.1486 - val_categorical_accuracy: 0.2481\n",
            "Epoch 170/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1454 - categorical_accuracy: 0.2644 - val_loss: 0.1480 - val_categorical_accuracy: 0.2523\n",
            "Epoch 171/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1449 - categorical_accuracy: 0.2674 - val_loss: 0.1478 - val_categorical_accuracy: 0.2526\n",
            "Epoch 172/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1448 - categorical_accuracy: 0.2677 - val_loss: 0.1481 - val_categorical_accuracy: 0.2505\n",
            "Epoch 173/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1451 - categorical_accuracy: 0.2659 - val_loss: 0.1485 - val_categorical_accuracy: 0.2489\n",
            "Epoch 174/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1450 - categorical_accuracy: 0.2669 - val_loss: 0.1475 - val_categorical_accuracy: 0.2539\n",
            "Epoch 175/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1449 - categorical_accuracy: 0.2671 - val_loss: 0.1475 - val_categorical_accuracy: 0.2540\n",
            "Epoch 176/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1447 - categorical_accuracy: 0.2681 - val_loss: 0.1478 - val_categorical_accuracy: 0.2524\n",
            "Epoch 177/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1448 - categorical_accuracy: 0.2678 - val_loss: 0.1490 - val_categorical_accuracy: 0.2469\n",
            "Epoch 178/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1452 - categorical_accuracy: 0.2657 - val_loss: 0.1480 - val_categorical_accuracy: 0.2512\n",
            "Epoch 179/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1446 - categorical_accuracy: 0.2688 - val_loss: 0.1475 - val_categorical_accuracy: 0.2538\n",
            "Epoch 180/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1447 - categorical_accuracy: 0.2682 - val_loss: 0.1478 - val_categorical_accuracy: 0.2529\n",
            "Epoch 181/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1446 - categorical_accuracy: 0.2683 - val_loss: 0.1481 - val_categorical_accuracy: 0.2515\n",
            "Epoch 182/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1449 - categorical_accuracy: 0.2673 - val_loss: 0.1478 - val_categorical_accuracy: 0.2534\n",
            "Epoch 183/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1442 - categorical_accuracy: 0.2705 - val_loss: 0.1477 - val_categorical_accuracy: 0.2530\n",
            "Epoch 184/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1447 - categorical_accuracy: 0.2681 - val_loss: 0.1479 - val_categorical_accuracy: 0.2519\n",
            "Epoch 185/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1446 - categorical_accuracy: 0.2687 - val_loss: 0.1473 - val_categorical_accuracy: 0.2554\n",
            "Epoch 186/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1440 - categorical_accuracy: 0.2714 - val_loss: 0.1476 - val_categorical_accuracy: 0.2536\n",
            "Epoch 187/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1443 - categorical_accuracy: 0.2698 - val_loss: 0.1479 - val_categorical_accuracy: 0.2523\n",
            "Epoch 188/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1445 - categorical_accuracy: 0.2689 - val_loss: 0.1478 - val_categorical_accuracy: 0.2525\n",
            "Epoch 189/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1442 - categorical_accuracy: 0.2702 - val_loss: 0.1472 - val_categorical_accuracy: 0.2551\n",
            "Epoch 190/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1445 - categorical_accuracy: 0.2688 - val_loss: 0.1475 - val_categorical_accuracy: 0.2543\n",
            "Epoch 191/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1440 - categorical_accuracy: 0.2712 - val_loss: 0.1476 - val_categorical_accuracy: 0.2536\n",
            "Epoch 192/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1442 - categorical_accuracy: 0.2698 - val_loss: 0.1480 - val_categorical_accuracy: 0.2522\n",
            "Epoch 193/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1438 - categorical_accuracy: 0.2720 - val_loss: 0.1478 - val_categorical_accuracy: 0.2524\n",
            "Epoch 194/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1438 - categorical_accuracy: 0.2724 - val_loss: 0.1473 - val_categorical_accuracy: 0.2548\n",
            "Epoch 195/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1442 - categorical_accuracy: 0.2702 - val_loss: 0.1471 - val_categorical_accuracy: 0.2558\n",
            "Epoch 196/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1440 - categorical_accuracy: 0.2714 - val_loss: 0.1485 - val_categorical_accuracy: 0.2494\n",
            "Epoch 197/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1452 - categorical_accuracy: 0.2655 - val_loss: 0.1473 - val_categorical_accuracy: 0.2545\n",
            "Epoch 198/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1441 - categorical_accuracy: 0.2711 - val_loss: 0.1471 - val_categorical_accuracy: 0.2558\n",
            "Epoch 199/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1443 - categorical_accuracy: 0.2701 - val_loss: 0.1472 - val_categorical_accuracy: 0.2556\n",
            "Epoch 200/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1436 - categorical_accuracy: 0.2733 - val_loss: 0.1475 - val_categorical_accuracy: 0.2548\n",
            "Epoch 201/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1440 - categorical_accuracy: 0.2718 - val_loss: 0.1470 - val_categorical_accuracy: 0.2563\n",
            "Epoch 202/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1435 - categorical_accuracy: 0.2737 - val_loss: 0.1475 - val_categorical_accuracy: 0.2535\n",
            "Epoch 203/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1435 - categorical_accuracy: 0.2738 - val_loss: 0.1473 - val_categorical_accuracy: 0.2548\n",
            "Epoch 204/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1439 - categorical_accuracy: 0.2724 - val_loss: 0.1471 - val_categorical_accuracy: 0.2564\n",
            "Epoch 205/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1447 - categorical_accuracy: 0.2681 - val_loss: 0.1469 - val_categorical_accuracy: 0.2575\n",
            "Epoch 206/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1443 - categorical_accuracy: 0.2700 - val_loss: 0.1474 - val_categorical_accuracy: 0.2538\n",
            "Epoch 207/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1439 - categorical_accuracy: 0.2721 - val_loss: 0.1472 - val_categorical_accuracy: 0.2563\n",
            "Epoch 208/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1444 - categorical_accuracy: 0.2701 - val_loss: 0.1472 - val_categorical_accuracy: 0.2551\n",
            "Epoch 209/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1437 - categorical_accuracy: 0.2731 - val_loss: 0.1474 - val_categorical_accuracy: 0.2543\n",
            "Epoch 210/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1435 - categorical_accuracy: 0.2737 - val_loss: 0.1466 - val_categorical_accuracy: 0.2576\n",
            "Epoch 211/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1438 - categorical_accuracy: 0.2725 - val_loss: 0.1467 - val_categorical_accuracy: 0.2586\n",
            "Epoch 212/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1429 - categorical_accuracy: 0.2767 - val_loss: 0.1469 - val_categorical_accuracy: 0.2567\n",
            "Epoch 213/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1434 - categorical_accuracy: 0.2752 - val_loss: 0.1469 - val_categorical_accuracy: 0.2570\n",
            "Epoch 214/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1433 - categorical_accuracy: 0.2755 - val_loss: 0.1470 - val_categorical_accuracy: 0.2563\n",
            "Epoch 215/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1433 - categorical_accuracy: 0.2759 - val_loss: 0.1470 - val_categorical_accuracy: 0.2570\n",
            "Epoch 216/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1433 - categorical_accuracy: 0.2750 - val_loss: 0.1469 - val_categorical_accuracy: 0.2571\n",
            "Epoch 217/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1436 - categorical_accuracy: 0.2731 - val_loss: 0.1469 - val_categorical_accuracy: 0.2571\n",
            "Epoch 218/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1433 - categorical_accuracy: 0.2746 - val_loss: 0.1465 - val_categorical_accuracy: 0.2589\n",
            "Epoch 219/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1430 - categorical_accuracy: 0.2768 - val_loss: 0.1471 - val_categorical_accuracy: 0.2562\n",
            "Epoch 220/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1436 - categorical_accuracy: 0.2736 - val_loss: 0.1470 - val_categorical_accuracy: 0.2570\n",
            "Epoch 221/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1432 - categorical_accuracy: 0.2754 - val_loss: 0.1463 - val_categorical_accuracy: 0.2600\n",
            "Epoch 222/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1430 - categorical_accuracy: 0.2759 - val_loss: 0.1464 - val_categorical_accuracy: 0.2595\n",
            "Epoch 223/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1438 - categorical_accuracy: 0.2726 - val_loss: 0.1467 - val_categorical_accuracy: 0.2576\n",
            "Epoch 224/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1432 - categorical_accuracy: 0.2759 - val_loss: 0.1471 - val_categorical_accuracy: 0.2561\n",
            "Epoch 225/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1436 - categorical_accuracy: 0.2737 - val_loss: 0.1469 - val_categorical_accuracy: 0.2577\n",
            "Epoch 226/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1429 - categorical_accuracy: 0.2767 - val_loss: 0.1469 - val_categorical_accuracy: 0.2565\n",
            "Epoch 227/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1428 - categorical_accuracy: 0.2779 - val_loss: 0.1472 - val_categorical_accuracy: 0.2547\n",
            "Epoch 228/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1433 - categorical_accuracy: 0.2745 - val_loss: 0.1464 - val_categorical_accuracy: 0.2584\n",
            "Epoch 229/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1425 - categorical_accuracy: 0.2790 - val_loss: 0.1464 - val_categorical_accuracy: 0.2601\n",
            "Epoch 230/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1427 - categorical_accuracy: 0.2780 - val_loss: 0.1467 - val_categorical_accuracy: 0.2577\n",
            "Epoch 231/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1425 - categorical_accuracy: 0.2789 - val_loss: 0.1465 - val_categorical_accuracy: 0.2593\n",
            "Epoch 232/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1429 - categorical_accuracy: 0.2763 - val_loss: 0.1467 - val_categorical_accuracy: 0.2579\n",
            "Epoch 233/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1426 - categorical_accuracy: 0.2780 - val_loss: 0.1466 - val_categorical_accuracy: 0.2588\n",
            "Epoch 234/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1424 - categorical_accuracy: 0.2795 - val_loss: 0.1462 - val_categorical_accuracy: 0.2600\n",
            "Epoch 235/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1431 - categorical_accuracy: 0.2758 - val_loss: 0.1463 - val_categorical_accuracy: 0.2596\n",
            "Epoch 236/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1425 - categorical_accuracy: 0.2786 - val_loss: 0.1465 - val_categorical_accuracy: 0.2598\n",
            "Epoch 237/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1424 - categorical_accuracy: 0.2793 - val_loss: 0.1468 - val_categorical_accuracy: 0.2569\n",
            "Epoch 238/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1427 - categorical_accuracy: 0.2781 - val_loss: 0.1462 - val_categorical_accuracy: 0.2600\n",
            "Epoch 239/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1423 - categorical_accuracy: 0.2798 - val_loss: 0.1465 - val_categorical_accuracy: 0.2592\n",
            "Epoch 240/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1427 - categorical_accuracy: 0.2777 - val_loss: 0.1461 - val_categorical_accuracy: 0.2606\n",
            "Epoch 241/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1426 - categorical_accuracy: 0.2779 - val_loss: 0.1461 - val_categorical_accuracy: 0.2608\n",
            "Epoch 242/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1427 - categorical_accuracy: 0.2776 - val_loss: 0.1463 - val_categorical_accuracy: 0.2597\n",
            "Epoch 243/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1425 - categorical_accuracy: 0.2789 - val_loss: 0.1458 - val_categorical_accuracy: 0.2620\n",
            "Epoch 244/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1421 - categorical_accuracy: 0.2808 - val_loss: 0.1457 - val_categorical_accuracy: 0.2618\n",
            "Epoch 245/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1427 - categorical_accuracy: 0.2774 - val_loss: 0.1454 - val_categorical_accuracy: 0.2637\n",
            "Epoch 246/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1417 - categorical_accuracy: 0.2826 - val_loss: 0.1458 - val_categorical_accuracy: 0.2626\n",
            "Epoch 247/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1424 - categorical_accuracy: 0.2791 - val_loss: 0.1454 - val_categorical_accuracy: 0.2634\n",
            "Epoch 248/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1419 - categorical_accuracy: 0.2810 - val_loss: 0.1450 - val_categorical_accuracy: 0.2659\n",
            "Epoch 249/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1422 - categorical_accuracy: 0.2801 - val_loss: 0.1449 - val_categorical_accuracy: 0.2659\n",
            "Epoch 250/250\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.1414 - categorical_accuracy: 0.2844 - val_loss: 0.1453 - val_categorical_accuracy: 0.2646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIdkA6_53Vm"
      },
      "source": [
        "Baseline Report: Training takes a while with so much data so I was only able to get data for this one model. The model has 2 hidden layers with 1000 and 100 layers respectively both using ReLU for activation functions. The output layer has 10 nodes each corresponding to one class from the data labels and uses the softmax activation function. The input layer has 3072 (32x32x3) nodes that correspond to the 'flattened' version of each image. \n",
        "\n",
        "Results: In just 250 epochs the model was able to reach ~30% accuracy which is fairly low but it is still much better than random guessing. While the model's progress slowed after ~50 epochs, the accuracy was still increasing slowly which means training for longer will yield better results.\n",
        "\n",
        "Note: I started working on this project too late and I didn't have enough time to properly train and experiment with different models. This is what I have right before the deadline but I'll train more (hopefully) better models and submit them after the initial deadline"
      ]
    }
  ]
}